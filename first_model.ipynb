{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning file for unique IDs: split_data_parquet/train_000.parquet\n",
      "Scanning file for unique IDs: split_data_parquet/train_001.parquet\n",
      "Scanning file for unique IDs: split_data_parquet/train_002.parquet\n",
      "Scanning file for unique IDs: split_data_parquet/train_003.parquet\n",
      "Scanning file for unique IDs: split_data_parquet/train_004.parquet\n",
      "Scanning file for unique IDs: split_data_parquet/train_005.parquet\n",
      "Scanning file for unique IDs: split_data_parquet/train_006.parquet\n",
      "Scanning file for unique IDs: split_data_parquet/train_007.parquet\n",
      "Scanning file for unique IDs: split_data_parquet/train_008.parquet\n",
      "Scanning file for unique IDs: split_data_parquet/train_009.parquet\n",
      "Scanning file for unique IDs: split_data_parquet/val_000.parquet\n",
      "Scanning file for unique IDs: split_data_parquet/val_001.parquet\n",
      "Scanning file for unique IDs: split_data_parquet/test_000.parquet\n",
      "Scanning file for unique IDs: split_data_parquet/test_001.parquet\n",
      "Number of unique players: 1543\n",
      "Example mapping: [(1713, 0), (2199, 1), (2544, 2), (2546, 3), (2594, 4), (2617, 5), (2730, 6), (2738, 7), (2772, 8), (101107, 9)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ players_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ player_embedding    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,344</span> │ players_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ offense_slice       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ player_embedding… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ defense_slice       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ player_embedding… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ off_mean (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ offense_slice[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ def_mean (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ defense_slice[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ off_mean[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ def_mean[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,176</span> │ concat[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ main_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,806</span> │ hidden[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ second_chance_out   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ hidden[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ players_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ player_embedding    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m8\u001b[0m)     │     \u001b[38;5;34m12,344\u001b[0m │ players_input[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ offense_slice       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ player_embedding… │\n",
       "│ (\u001b[38;5;33mLambda\u001b[0m)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ defense_slice       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ player_embedding… │\n",
       "│ (\u001b[38;5;33mLambda\u001b[0m)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ off_mean (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ offense_slice[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ def_mean (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ defense_slice[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ off_mean[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ def_mean[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hidden (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │      \u001b[38;5;34m2,176\u001b[0m │ concat[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ main_out (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)        │      \u001b[38;5;34m1,806\u001b[0m │ hidden[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ second_chance_out   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m129\u001b[0m │ hidden[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,455</span> (64.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,455\u001b[0m (64.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,455</span> (64.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,455\u001b[0m (64.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "Loading shard: split_data_parquet/train_000.parquet\n",
      "   2052/Unknown \u001b[1m10s\u001b[0m 4ms/step - loss: 2.6201 - main_out_accuracy: 0.3676 - main_out_loss: 2.1997 - second_chance_out_accuracy: 0.8579 - second_chance_out_loss: 0.4204Loading shard: split_data_parquet/train_001.parquet\n",
      "   4261/Unknown \u001b[1m19s\u001b[0m 4ms/step - loss: 2.5991 - main_out_accuracy: 0.3676 - main_out_loss: 2.1856 - second_chance_out_accuracy: 0.8589 - second_chance_out_loss: 0.4135Loading shard: split_data_parquet/train_002.parquet\n",
      "   6478/Unknown \u001b[1m28s\u001b[0m 4ms/step - loss: 2.5922 - main_out_accuracy: 0.3672 - main_out_loss: 2.1812 - second_chance_out_accuracy: 0.8592 - second_chance_out_loss: 0.4111Loading shard: split_data_parquet/train_003.parquet\n",
      "   8689/Unknown \u001b[1m37s\u001b[0m 4ms/step - loss: 2.5886 - main_out_accuracy: 0.3669 - main_out_loss: 2.1789 - second_chance_out_accuracy: 0.8594 - second_chance_out_loss: 0.4097Loading shard: split_data_parquet/train_004.parquet\n",
      "  10901/Unknown \u001b[1m47s\u001b[0m 4ms/step - loss: 2.5862 - main_out_accuracy: 0.3668 - main_out_loss: 2.1773 - second_chance_out_accuracy: 0.8595 - second_chance_out_loss: 0.4089Loading shard: split_data_parquet/train_005.parquet\n",
      "  13107/Unknown \u001b[1m56s\u001b[0m 4ms/step - loss: 2.5844 - main_out_accuracy: 0.3667 - main_out_loss: 2.1761 - second_chance_out_accuracy: 0.8596 - second_chance_out_loss: 0.4082Loading shard: split_data_parquet/train_006.parquet\n",
      "  15321/Unknown \u001b[1m65s\u001b[0m 4ms/step - loss: 2.5829 - main_out_accuracy: 0.3666 - main_out_loss: 2.1751 - second_chance_out_accuracy: 0.8597 - second_chance_out_loss: 0.4078Loading shard: split_data_parquet/train_007.parquet\n",
      "  17532/Unknown \u001b[1m75s\u001b[0m 4ms/step - loss: 2.5816 - main_out_accuracy: 0.3666 - main_out_loss: 2.1741 - second_chance_out_accuracy: 0.8598 - second_chance_out_loss: 0.4074Loading shard: split_data_parquet/train_008.parquet\n",
      "  19747/Unknown \u001b[1m84s\u001b[0m 4ms/step - loss: 2.5804 - main_out_accuracy: 0.3666 - main_out_loss: 2.1732 - second_chance_out_accuracy: 0.8598 - second_chance_out_loss: 0.4072Loading shard: split_data_parquet/train_009.parquet\n",
      "  22036/Unknown \u001b[1m93s\u001b[0m 4ms/step - loss: 2.5792 - main_out_accuracy: 0.3666 - main_out_loss: 2.1722 - second_chance_out_accuracy: 0.8598 - second_chance_out_loss: 0.4070Loading shard: split_data_parquet/val_000.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-09 14:19:33.495162: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/opt/anaconda3/envs/nba_capston/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shard: split_data_parquet/val_001.parquet\n",
      "\u001b[1m22126/22126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 5ms/step - loss: 2.5792 - main_out_accuracy: 0.3666 - main_out_loss: 2.1722 - second_chance_out_accuracy: 0.8598 - second_chance_out_loss: 0.4070 - val_loss: 2.5569 - val_main_out_accuracy: 0.3679 - val_main_out_loss: 2.1478 - val_second_chance_out_accuracy: 0.8582 - val_second_chance_out_loss: 0.4082\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-09 14:19:44.763712: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/opt/anaconda3/envs/nba_capston/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shard: split_data_parquet/train_000.parquet\n",
      "\u001b[1m 2055/22126\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:24\u001b[0m 4ms/step - loss: 2.5491 - main_out_accuracy: 0.3699 - main_out_loss: 2.1435 - second_chance_out_accuracy: 0.8597 - second_chance_out_loss: 0.4056Loading shard: split_data_parquet/train_001.parquet\n",
      "\u001b[1m 4268/22126\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:15\u001b[0m 4ms/step - loss: 2.5503 - main_out_accuracy: 0.3690 - main_out_loss: 2.1449 - second_chance_out_accuracy: 0.8598 - second_chance_out_loss: 0.4054Loading shard: split_data_parquet/train_002.parquet\n",
      "\u001b[1m 6473/22126\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:06\u001b[0m 4ms/step - loss: 2.5517 - main_out_accuracy: 0.3682 - main_out_loss: 2.1463 - second_chance_out_accuracy: 0.8598 - second_chance_out_loss: 0.4053Loading shard: split_data_parquet/train_003.parquet\n",
      "\u001b[1m 8686/22126\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m57s\u001b[0m 4ms/step - loss: 2.5523 - main_out_accuracy: 0.3677 - main_out_loss: 2.1471 - second_chance_out_accuracy: 0.8599 - second_chance_out_loss: 0.4052Loading shard: split_data_parquet/train_004.parquet\n",
      "\u001b[1m10906/22126\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m47s\u001b[0m 4ms/step - loss: 2.5526 - main_out_accuracy: 0.3674 - main_out_loss: 2.1475 - second_chance_out_accuracy: 0.8599 - second_chance_out_loss: 0.4051Loading shard: split_data_parquet/train_005.parquet\n",
      "\u001b[1m13111/22126\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - loss: 2.5526 - main_out_accuracy: 0.3672 - main_out_loss: 2.1476 - second_chance_out_accuracy: 0.8600 - second_chance_out_loss: 0.4050Loading shard: split_data_parquet/train_006.parquet\n",
      "\u001b[1m15320/22126\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - loss: 2.5526 - main_out_accuracy: 0.3671 - main_out_loss: 2.1477 - second_chance_out_accuracy: 0.8600 - second_chance_out_loss: 0.4049Loading shard: split_data_parquet/train_007.parquet\n",
      "\u001b[1m17536/22126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - loss: 2.5525 - main_out_accuracy: 0.3670 - main_out_loss: 2.1476 - second_chance_out_accuracy: 0.8600 - second_chance_out_loss: 0.4049Loading shard: split_data_parquet/train_008.parquet\n",
      "\u001b[1m19747/22126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - loss: 2.5524 - main_out_accuracy: 0.3670 - main_out_loss: 2.1476 - second_chance_out_accuracy: 0.8600 - second_chance_out_loss: 0.4048Loading shard: split_data_parquet/train_009.parquet\n",
      "\u001b[1m22103/22126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5523 - main_out_accuracy: 0.3669 - main_out_loss: 2.1475 - second_chance_out_accuracy: 0.8600 - second_chance_out_loss: 0.4048Loading shard: split_data_parquet/val_000.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nba_capston/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shard: split_data_parquet/val_001.parquet\n",
      "\u001b[1m22126/22126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 5ms/step - loss: 2.5523 - main_out_accuracy: 0.3669 - main_out_loss: 2.1475 - second_chance_out_accuracy: 0.8600 - second_chance_out_loss: 0.4048 - val_loss: 2.5511 - val_main_out_accuracy: 0.3679 - val_main_out_loss: 2.1426 - val_second_chance_out_accuracy: 0.8582 - val_second_chance_out_loss: 0.4075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-09 14:21:32.381126: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/opt/anaconda3/envs/nba_capston/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shard: split_data_parquet/test_000.parquet\n",
      "   1218/Unknown \u001b[1m6s\u001b[0m 5ms/step - loss: 2.5522 - main_out_accuracy: 0.3633 - main_out_loss: 2.1478 - second_chance_out_accuracy: 0.8600 - second_chance_out_loss: 0.4045Loading shard: split_data_parquet/test_001.parquet\n",
      "\u001b[1m2766/2766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 2.5500 - main_out_accuracy: 0.3653 - main_out_loss: 2.1452 - second_chance_out_accuracy: 0.8598 - second_chance_out_loss: 0.4048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nba_capston/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.5476553440093994,\n",
       " 2.142456293106079,\n",
       " 0.40430155396461487,\n",
       " 0.3672352135181427,\n",
       " 0.8599838614463806]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "##############################################\n",
    "# Parameters & Setup\n",
    "##############################################\n",
    "seq_len = 10\n",
    "embedding_dim = 8\n",
    "batch_size = 64\n",
    "data_dir = 'split_data_parquet'\n",
    "\n",
    "player_columns = [\n",
    "    \"OFF_PLAYER1_ID\", \"OFF_PLAYER2_ID\", \"OFF_PLAYER3_ID\", \"OFF_PLAYER4_ID\", \"OFF_PLAYER5_ID\",\n",
    "    \"DEF_PLAYER1_ID\", \"DEF_PLAYER2_ID\", \"DEF_PLAYER3_ID\", \"DEF_PLAYER4_ID\", \"DEF_PLAYER5_ID\"\n",
    "]\n",
    "\n",
    "main_out_column = \"OUTCOME\"\n",
    "second_chance_column = \"SECOND_CHANCE\"\n",
    "unwanted_cols = [\"SHOOTER_ID\",\"ASSISTER_ID\",\"BLOCKER_ID\",\"STEALER_ID\",\"REBOUNDER_ID\",\"TURNOVER_ID\"]\n",
    "\n",
    "# Identify shard files\n",
    "train_files = sorted([os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.startswith('train_') and f.endswith('.parquet')])\n",
    "val_files = sorted([os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.startswith('val_') and f.endswith('.parquet')])\n",
    "test_files = sorted([os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.startswith('test_') and f.endswith('.parquet')])\n",
    "\n",
    "##############################################\n",
    "# Build Player ID Mapping\n",
    "##############################################\n",
    "def gather_unique_player_ids(files, player_cols):\n",
    "    unique_ids = set()\n",
    "    for fpath in files:\n",
    "        print(f\"Scanning file for unique IDs: {fpath}\")\n",
    "        df = pd.read_parquet(fpath, columns=player_cols)  # load only player columns\n",
    "        df = df.dropna(subset=player_cols)\n",
    "        for col in player_cols:\n",
    "            unique_ids.update(df[col].dropna().astype(int).unique())\n",
    "    return unique_ids\n",
    "\n",
    "all_files = train_files + val_files + test_files\n",
    "all_unique_ids = gather_unique_player_ids(all_files, player_columns)\n",
    "\n",
    "unique_players = np.sort(list(all_unique_ids))\n",
    "player_to_index = {p: i for i, p in enumerate(unique_players)}\n",
    "v = len(unique_players)\n",
    "print(f\"Number of unique players: {v}\")\n",
    "print(\"Example mapping:\", list(player_to_index.items())[:10])\n",
    "\n",
    "##############################################\n",
    "# Model Definition Using Embeddings (with updated v)\n",
    "##############################################\n",
    "input_players = Input(shape=(seq_len,), dtype='int32', name='players_input')\n",
    "player_embedding = layers.Embedding(input_dim=v, output_dim=embedding_dim, name='player_embedding')(input_players)\n",
    "\n",
    "offense_emb = layers.Lambda(lambda t: t[:, :5, :], name='offense_slice')(player_embedding)\n",
    "defense_emb = layers.Lambda(lambda t: t[:, 5:, :], name='defense_slice')(player_embedding)\n",
    "\n",
    "off_mean = layers.Lambda(lambda t: tf.reduce_mean(t, axis=1), name='off_mean')(offense_emb)\n",
    "def_mean = layers.Lambda(lambda t: tf.reduce_mean(t, axis=1), name='def_mean')(defense_emb)\n",
    "\n",
    "concat = layers.Concatenate(name='concat')([off_mean, def_mean])\n",
    "hidden = layers.Dense(128, activation='relu', name='hidden')(concat)\n",
    "\n",
    "main_out = layers.Dense(14, activation='softmax', name='main_out')(hidden)\n",
    "second_chance_out = layers.Dense(1, activation='sigmoid', name='second_chance_out')(hidden)\n",
    "\n",
    "# Set a custom learning rate\n",
    "# optimizer = Adam(learning_rate=0.0001)\n",
    "optimizer = SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "model = Model(inputs=input_players, outputs=[main_out, second_chance_out])\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss={\n",
    "        'main_out': 'categorical_crossentropy',\n",
    "        'second_chance_out': 'binary_crossentropy'\n",
    "    },\n",
    "    metrics={\n",
    "        'main_out': 'accuracy',\n",
    "        'second_chance_out': 'accuracy'\n",
    "    }\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "##############################################\n",
    "# Utility Functions for tf.data Pipeline\n",
    "##############################################\n",
    "def shard_generator(file_list, main_col, sc_col, mapping):\n",
    "    \"\"\"\n",
    "    Yields individual samples (X, (y_main, y_sc)) from shard files.\n",
    "    Applies player_to_index mapping to ensure IDs are in [0, v-1].\n",
    "    \"\"\"\n",
    "    for fpath in file_list:\n",
    "        print(f\"Loading shard: {fpath}\")\n",
    "        df = pd.read_parquet(fpath)\n",
    "\n",
    "        # Drop rows with NaNs in player columns\n",
    "        df = df.dropna(subset=player_columns)\n",
    "\n",
    "        # Convert players to int\n",
    "        for col in player_columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "        # Drop unwanted columns\n",
    "        for c in unwanted_cols:\n",
    "            if c in df.columns:\n",
    "                df.drop(columns=c, inplace=True)\n",
    "\n",
    "        # One-hot the outcome column\n",
    "        categories = sorted(df[main_col].unique())\n",
    "        cat_to_idx = {cat: i for i, cat in enumerate(categories)}\n",
    "\n",
    "        num_samples = len(df)\n",
    "        y_main = np.zeros((num_samples, 14), dtype='float32')\n",
    "        for i, val in enumerate(df[main_col]):\n",
    "            class_idx = cat_to_idx[val]\n",
    "            y_main[i, class_idx] = 1.0\n",
    "\n",
    "        y_sc = df[sc_col].astype(int).values.reshape(-1, 1)\n",
    "\n",
    "        # Drop target columns now\n",
    "        df.drop(columns=[main_col, sc_col], inplace=True)\n",
    "\n",
    "        # Map player IDs\n",
    "        for c in player_columns:\n",
    "            df[c] = df[c].map(mapping)\n",
    "\n",
    "        X = df[player_columns].values.astype(np.int32)\n",
    "\n",
    "        # Yield each sample\n",
    "        for i in range(num_samples):\n",
    "            yield X[i], (y_main[i], y_sc[i])\n",
    "\n",
    "def create_dataset(file_list, main_col, sc_col, batch_size, mapping, shuffle_buffer=10000):\n",
    "    ds = tf.data.Dataset.from_generator(\n",
    "        lambda: shard_generator(file_list, main_col, sc_col, mapping),\n",
    "        output_types=(tf.int32, (tf.float32, tf.float32)),\n",
    "        output_shapes=((seq_len,), ((14,), (1,)))\n",
    "    )\n",
    "\n",
    "    ds = ds.shuffle(shuffle_buffer)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "##############################################\n",
    "# Create Datasets using mapping\n",
    "##############################################\n",
    "train_ds = create_dataset(train_files, main_out_column, second_chance_column, batch_size, player_to_index)\n",
    "val_ds = create_dataset(val_files, main_out_column, second_chance_column, batch_size, player_to_index)\n",
    "test_ds = create_dataset(test_files, main_out_column, second_chance_column, batch_size, player_to_index)\n",
    "\n",
    "##############################################\n",
    "# Training with tf.data\n",
    "##############################################\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=2\n",
    ")\n",
    "\n",
    "##############################################\n",
    "# Evaluation\n",
    "##############################################\n",
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved player embeddings to player_embeddings.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# After training the model and having player_to_index, unique_players defined:\n",
    "embedding_matrix = model.get_layer('player_embedding').get_weights()[0]\n",
    "\n",
    "# Create a DataFrame for player embeddings\n",
    "# Columns: ['player_id', 'embed_0', 'embed_1', ..., 'embed_{embedding_dim-1}']\n",
    "columns = ['player_id'] + [f'embed_{d}' for d in range(embedding_matrix.shape[1])]\n",
    "\n",
    "data = []\n",
    "for p, i in player_to_index.items():\n",
    "    # embedding_matrix[i] is the embedding vector for player p\n",
    "    row = [p] + embedding_matrix[i].tolist()\n",
    "    data.append(row)\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Save to a CSV file\n",
    "output_csv = 'player_embeddings.csv'\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Saved player embeddings to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from nba_api.stats.static import players\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# Load the embeddings from the CSV\n",
    "df = pd.read_csv('player_embeddings.csv')  # Ensure the CSV path is correct\n",
    "\n",
    "player_ids = df['player_id'].values\n",
    "# Extract embedding columns (all except 'player_id')\n",
    "embedding_cols = [c for c in df.columns if c.startswith('embed_')]\n",
    "vectors = df[embedding_cols].values  # shape (num_players, embedding_dim)\n",
    "\n",
    "# Run TSNE on vectors\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "tsne_coords = tsne.fit_transform(vectors)\n",
    "\n",
    "x_coords = tsne_coords[:, 0]\n",
    "y_coords = tsne_coords[:, 1]\n",
    "\n",
    "# Get NBA players list and create a dict id->full_name if your player_id matches nba_api ids\n",
    "all_nba_players = players.get_players()\n",
    "id_to_name = {p['id']: p['full_name'] for p in all_nba_players}\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(x_coords, y_coords, s=20)\n",
    "\n",
    "# We'll store text objects separately and then call adjust_text\n",
    "texts = []\n",
    "\n",
    "# Label the first 10 points (or any other selection logic)\n",
    "for i, pid in enumerate(player_ids):\n",
    "    if i < 10:\n",
    "        label = id_to_name.get(pid, str(pid))\n",
    "        # Instead of plt.text directly, we add them to a list\n",
    "        text_obj = plt.text(x_coords[i], y_coords[i], label, fontsize=9)\n",
    "        texts.append(text_obj)\n",
    "\n",
    "plt.title(\"Player Embeddings (t-SNE 2D Projection)\")\n",
    "plt.xlabel(\"Dimension 1\")\n",
    "plt.ylabel(\"Dimension 2\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Adjust text positions to avoid overlap\n",
    "adjust_text(texts, x=x_coords[:10], y=y_coords[:10], arrowprops=dict(arrowstyle='->', color='red', lw=0.5))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nba_capston",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
